{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["MeuvwAGH-Rwa","EnoCn_OA_1Yz"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"Gas-YKl-8HQg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0KrktUl19Oj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import plotly.express as px\n","pd.options.plotting.backend = 'plotly'\n","\n","# Code to read csv file into Colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')"],"metadata":{"id":"HvbfodyXq9HT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743875505,"user_tz":420,"elapsed":3226,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"103ba1e8-909e-4cad-aa73-fbf64f7e1a19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":[],"metadata":{"id":"O-RIsPOfq-Or"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Review Data"],"metadata":{"id":"KlGJYekSq6t_"}},{"cell_type":"markdown","source":["##Cleaning"],"metadata":{"id":"xhCECGCWA0Nc"}},{"cell_type":"markdown","source":["###Import the data from our google drive."],"metadata":{"id":"IkfK1KUp-YaB"}},{"cell_type":"code","source":["reviews_id = '1itcJ-cExPpHZea7c8hjPMYM6T4l8Z_0w'\n","downloaded = drive.CreateFile({'id':reviews_id})\n","downloaded.GetContentFile('filtered-reviews.csv')\n","reviews = pd.read_csv('filtered-reviews.csv')"],"metadata":{"id":"mNQzEawDq8UN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Generate a breif overview of the dataframe."],"metadata":{"id":"D1cfsdqc-es8"}},{"cell_type":"code","source":["reviews.describe()"],"metadata":{"id":"AUiLJgRc-Jlj","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1685743905249,"user_tz":420,"elapsed":5721,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"db377b59-7ff0-4fc0-eb0e-a6c399e1561f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     review_id                 user_id  \\\n","count                   327819                  327819   \n","unique                  327819                  228555   \n","top     l3Wk_mvAog6XANIuGQ9C7Q  CfX4sTIFFNaRchNswqhVfg   \n","freq                         1                      57   \n","\n","                   business_id  \\\n","count                   327819   \n","unique                     237   \n","top     2BMk_drsikKWslJCXmQtjQ   \n","freq                      2023   \n","\n","                                                     text                 date  \n","count                                              327819               327819  \n","unique                                             327238               327552  \n","top     Omg!There's food was good!Ryan is awesome away...  2014-06-22 00:49:26  \n","freq                                                    7                    3  "],"text/html":["\n","  <div id=\"df-211b4905-bdc0-4f34-87d9-53cd5ed95118\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>user_id</th>\n","      <th>business_id</th>\n","      <th>text</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>327819</td>\n","      <td>327819</td>\n","      <td>327819</td>\n","      <td>327819</td>\n","      <td>327819</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>327819</td>\n","      <td>228555</td>\n","      <td>237</td>\n","      <td>327238</td>\n","      <td>327552</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>l3Wk_mvAog6XANIuGQ9C7Q</td>\n","      <td>CfX4sTIFFNaRchNswqhVfg</td>\n","      <td>2BMk_drsikKWslJCXmQtjQ</td>\n","      <td>Omg!There's food was good!Ryan is awesome away...</td>\n","      <td>2014-06-22 00:49:26</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>57</td>\n","      <td>2023</td>\n","      <td>7</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-211b4905-bdc0-4f34-87d9-53cd5ed95118')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-211b4905-bdc0-4f34-87d9-53cd5ed95118 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-211b4905-bdc0-4f34-87d9-53cd5ed95118');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Notes:\n","\n","\n","*   All review ids seem to be unique\n","*   There seem to be around 230k unique users writing reviews\n","* There are 237 unique businesses represented in the data\n","* Oddly, there seem to be a few hundred reviews with coppied text\n","* There are a couple hundred cases where the dates are the same, this is likely due to random change. (Should be verified with a hypothesis test)\n","\n"],"metadata":{"id":"NAywSkk5-XMx"}},{"cell_type":"markdown","source":["###Check for null values"],"metadata":{"id":"MeuvwAGH-Rwa"}},{"cell_type":"code","source":["reviews.isna().sum()"],"metadata":{"id":"0A2t8dRr-Nju","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743906578,"user_tz":420,"elapsed":1333,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"b4090e76-85c5-406f-87fc-55797aa6ed2a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["review_id      0\n","user_id        0\n","business_id    0\n","text           0\n","date           0\n","dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Seems like there are no notable nulls in our data."],"metadata":{"id":"xnDp4Q4Q_vgU"}},{"cell_type":"markdown","source":["###Fix Datatypes"],"metadata":{"id":"EnoCn_OA_1Yz"}},{"cell_type":"code","source":["\n","reviews.dtypes"],"metadata":{"id":"HZiLc0QIrcMf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743906862,"user_tz":420,"elapsed":292,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"89b255fa-c6f3-411b-bc54-9a0f3b04d5af"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["review_id      object\n","user_id        object\n","business_id    object\n","text           object\n","date           object\n","dtype: object"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["It looks like everything imported as an object. We will leave most of these untouched, except the date column which needs to be converted to a datetime to become useful."],"metadata":{"id":"SABgHQM5__tR"}},{"cell_type":"code","source":["reviews['date'] = pd.to_datetime(reviews['date'])"],"metadata":{"id":"ABPrwVmxrdR_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reviews.dtypes"],"metadata":{"id":"oE4UHaxt-FHC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743907589,"user_tz":420,"elapsed":6,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"731e90e3-cf70-43bd-9dd5-7136d6dc23b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["review_id              object\n","user_id                object\n","business_id            object\n","text                   object\n","date           datetime64[ns]\n","dtype: object"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Language Model"],"metadata":{"id":"V6gpAj-JBkCc"}},{"cell_type":"code","source":["business_series = pd.Series(reviews[\"business_id\"].unique())\n","random_business = business_series[0]\n","random_business"],"metadata":{"id":"xzrOQwCdLi1d","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1685743907747,"user_tz":420,"elapsed":162,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"6c49592b-5940-4a21-fe47-4913df5e3e1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'EQ-TZ2eeD_E0BHuvoaeG5Q'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["reviews_filtered = reviews[reviews['business_id'] == random_business]"],"metadata":{"id":"O1FXgAPRMr3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_reviews = reviews_filtered['text'].apply(lambda doc: nltk.word_tokenize(doc))\n","tokenized_reviews"],"metadata":{"id":"ZV_tH0DjBliF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743910150,"user_tz":420,"elapsed":2408,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"fd16b4c2-fe88-42aa-caae-ced7ea098997"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        [Locals, recommended, Milktooth, ,, and, it, '...\n","13       [Milktooth, is, the, place, to, go, if, you, w...\n","37       [Busy, place, ,, but, we, were, offered, extra...\n","62       [Creative, food, and, good, ., We, get, coffee...\n","82       [Amazing, and, comfortable, atmosphere, with, ...\n","                               ...                        \n","41497    [Nice, and, freely, staff, ., Was, a, bit, dis...\n","41529    [Arrived, at, 1:30pm, ., Walked, around, looki...\n","41532    [Verdict, :, A, good, brunch, spot, to, try, n...\n","41533    [For, a, picky, eater, ,, this, place, is, ter...\n","41535    [So, I, 've, been, here, twice, ..., This, pla...\n","Name: text, Length: 1421, dtype: object"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from nltk.util import ngrams\n","\n","trigrams = []\n","for tokens in tokenized_reviews:\n","    trigrams.extend(list(ngrams(tokens, 3, pad_left=True, pad_right=True)))\n","trigrams"],"metadata":{"id":"_rilLxKgNLHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.util import ngrams\n","\n","bigrams = []\n","for tokens in tokenized_reviews:\n","    bigrams.extend(list(ngrams(tokens, 2, pad_left=True, pad_right=True)))\n","bigrams"],"metadata":{"id":"K_YRU7x_F0fQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.util import ngrams\n","\n","unigrams = []\n","for tokens in tokenized_reviews:\n","    unigrams.extend(list(ngrams(tokens, 1, pad_left=True, pad_right=True)))\n","unigrams"],"metadata":{"id":"-VyXHX3hF5q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","unigram_counts = Counter(unigrams)\n","total_unigrams = sum(unigram_counts.values())\n","unigram_probabilities = {\n","    unigram: count / total_unigrams\n","    for unigram, count in unigram_counts.items()\n","}\n","assert abs(sum(unigram_probabilities.values()) - 1) < 1e-6\n","unigram_probabilities"],"metadata":{"id":"I5BP3q_mGQME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","bigram_counts = Counter(bigrams)\n","total_bigrams = sum(bigram_counts.values())\n","bigram_probabilities = {\n","    # might need to change to the count of bigram / count of first word in current bigram\n","    # bigram: count /\n","    bigram: count / total_bigrams\n","    for bigram, count in bigram_counts.items()\n","}\n","assert abs(sum(bigram_probabilities.values()) - 1) < 1e-6\n","bigram_probabilities"],"metadata":{"id":"bskekxgYGRKS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","trigram_counts = Counter(trigrams)\n","total_trigrams = sum(trigram_counts.values())\n","trigram_probabilities = {\n","    # might need to chang to count of trigram / count of beginning bigram in trigram\n","    trigram: count / total_trigrams\n","    for trigram, count in trigram_counts.items()\n","}\n","assert abs(sum(trigram_probabilities.values()) - 1) < 1e-6\n","trigram_probabilities"],"metadata":{"id":"qpZQpC4yGVf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["token_list = []\n","for review in tokenized_reviews:\n","  for word in review:\n","    token_list.append(word)\n","token_list"],"metadata":{"id":"bKHCE7aTIJFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UnigramLM(object):\n","\n","    def __init__(self, tokens):\n","\n","        self.mdl = self.train(tokens)\n","\n","    def train(self, tokens):\n","        out = pd.Series(tokens).value_counts()\n","        return out / out.sum()\n","\n","    def probability(self, words):\n","        prod = 1\n","        for token in words:\n","            if token in self.mdl: prod *= self.mdl[token]\n","            else: return 0\n","        return prod\n","\n","    def sample(self, M):\n","        return ' '.join(\n","            [\n","                np.random.choice(self.mdl.index, p=self.mdl.to_numpy()) \\\n","                for _ in range(M)\n","            ])\n","\n","\n","class NGramLM(object):\n","\n","    def __init__(self, N, tokens):\n","        # You don't need to edit the constructor,\n","        # but you should understand how it works!\n","\n","        self.N = N\n","\n","        ngrams = self.create_ngrams(tokens)\n","\n","        self.ngrams = ngrams\n","        #print(ngrams)\n","\n","        self.mdl = self.train(ngrams)\n","        print(self.mdl)\n","\n","        if N < 2:\n","            raise Exception('N must be greater than 1')\n","        elif N == 2:\n","            self.prev_mdl = UnigramLM(tokens)\n","        else:\n","            self.prev_mdl = NGramLM(N-1, tokens)\n","\n","    def create_ngrams(self, tokens):\n","        out = []\n","        for i in range(0, len(tokens) - (self.N - 1)):\n","            out.append(tuple(tokens[i:i + self.N]))\n","        return out\n","\n","\n","    def train(self, ngrams):\n","        ngrams = pd.Series(ngrams)\n","        n1grams = ngrams.apply(lambda x: x[0:self.N - 1])\n","        #print(n1grams)\n","\n","        ngram_counts = ngrams.value_counts()\n","        n1gram_counts = n1grams.value_counts()\n","        #print(n1gram_counts)\n","\n","        df = pd.DataFrame().assign(\n","            ngram = ngrams,\n","            n1gram = n1grams)\n","        df['prob'] = df.apply(\n","            lambda x: ngram_counts[x.ngram] / n1gram_counts[x.n1gram], axis=1)\n","\n","        df = df.drop_duplicates(subset='ngram', keep='first')\n","\n","        return df\n","\n","\n","    def probability(self, words):\n","        words = tuple(words)\n","        current = self\n","        total = 1\n","        for i in range(0, len(words) - self.N + 1):\n","            p = words[i:i+self.N]\n","            p1 = p[0:-1]\n","            try:\n","                prob = current.mdl.loc[\n","                    (current.mdl['ngram'] == p) &\n","                    (current.mdl['n1gram'] == p1), 'prob'\n","                ].iloc[0]\n","            except:\n","                return 0\n","            total *= prob\n","\n","        start_index = self.N - 1\n","        if len(words) < self.N:\n","            for _ in range(self.N - len(words) - 1):\n","                current = current.prev_mdl\n","            start_index = len(words)\n","\n","        for i in range(start_index, 0, -1):\n","            current = current.prev_mdl\n","            p = words[0:i]\n","            p1 = p[0:i-1]\n","            try:\n","                if len(p1) == 0:\n","                    prob = current.mdl.loc[p]\n","                else:\n","                    prob = current.mdl.loc[\n","                        (current.mdl['ngram'] == p) &\n","                        (current.mdl['n1gram'] == p1), 'prob'\n","                    ].iloc[0]\n","            except:\n","                return 0\n","            total *= prob\n","\n","        return total\n","\n","\n","    def sample(self, M):\n","        # Use a helper function to generate sample tokens of length `length`\n","        def add_token(words):\n","            subset = words if len(words) < self.N else words[-self.N + 1:]\n","\n","            current = self\n","            for _ in range(self.N - len(subset) - 1):\n","                current = current.prev_mdl\n","\n","            # print(current.mdl.set_index('n1gram'))\n","            # print(subset, words)\n","            try:\n","                choices = current.mdl.set_index('n1gram').loc[[tuple(subset)]]\n","                out = choices['ngram'].sample(1, weights=choices['prob'])[0]\n","                return words[0:len(words) - len(out) + 1] + out\n","            except Exception as e:\n","                print(e)\n","                return words + ('\\x03',)\n","\n","\n","        def gen_sample(length):\n","            out = ('\\x02',)\n","            for _ in range(length - 1):\n","                out = out + ('\\x02',) if out[-1] == '\\x03' else add_token(out)\n","            return out + ('\\x03',)\n","\n","        # Transform the tokens to strings\n","        out = gen_sample(M)\n","        return ' '.join(out)\n","\n","\n","token_list2 = token_list[:10]\n","print(token_list2)\n","\n","threegram = NGramLM(3, token_list2)\n","sample = threegram.sample(5)"],"metadata":{"id":"o5ly-MtUGsj3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743911285,"user_tz":420,"elapsed":10,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"5d6ee277-d6f6-4099-8687-bc709b144abb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Locals', 'recommended', 'Milktooth', ',', 'and', 'it', \"'s\", 'an', 'amazing', 'jewel']\n","                              ngram                    n1gram  prob\n","0  (Locals, recommended, Milktooth)     (Locals, recommended)   1.0\n","1       (recommended, Milktooth, ,)  (recommended, Milktooth)   1.0\n","2               (Milktooth, ,, and)            (Milktooth, ,)   1.0\n","3                      (,, and, it)                  (,, and)   1.0\n","4                     (and, it, 's)                 (and, it)   1.0\n","5                      (it, 's, an)                  (it, 's)   1.0\n","6                 ('s, an, amazing)                  ('s, an)   1.0\n","7              (an, amazing, jewel)             (an, amazing)   1.0\n","                      ngram          n1gram  prob\n","0     (Locals, recommended)       (Locals,)   1.0\n","1  (recommended, Milktooth)  (recommended,)   1.0\n","2            (Milktooth, ,)    (Milktooth,)   1.0\n","3                  (,, and)            (,,)   1.0\n","4                 (and, it)          (and,)   1.0\n","5                  (it, 's)           (it,)   1.0\n","6                  ('s, an)           ('s,)   1.0\n","7             (an, amazing)           (an,)   1.0\n","8          (amazing, jewel)      (amazing,)   1.0\n","\"None of [Index([('\\x02',)], dtype='object', name='n1gram')] are in the [index]\"\n","\"None of [Index([('\\x03', '\\x02')], dtype='object', name='n1gram')] are in the [index]\"\n"]}]},{"cell_type":"code","source":["token_list2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJpN9h6OSR75","executionInfo":{"status":"ok","timestamp":1685743911285,"user_tz":420,"elapsed":5,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"72ea72c3-723e-4551-9d08-c1d0179b1e54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Locals',\n"," 'recommended',\n"," 'Milktooth',\n"," ',',\n"," 'and',\n"," 'it',\n"," \"'s\",\n"," 'an',\n"," 'amazing',\n"," 'jewel']"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["#Clustering"],"metadata":{"id":"EMULZD1HBnmG"}},{"cell_type":"markdown","source":["In this section we will be creating a clustering algorithm to understand the various types of reviews within our data and the relative frequencies of each review type we define."],"metadata":{"id":"t1s63RHuW7eD"}},{"cell_type":"markdown","source":["### Preprocessing\n","1. Find all reviews for a business.\n","2. Tokenize the reviews and find all unique tokens in the data.\n","3. Create a matrix of tf-idf vectors for each review.\n","\n"],"metadata":{"id":"3GXwvHX_DnY6"}},{"cell_type":"markdown","source":["#### 1. Find all reviews for a business.\n"],"metadata":{"id":"j-nz1qasUl8p"}},{"cell_type":"code","source":["business_series = pd.Series(reviews[\"business_id\"].unique())\n","business_x = business_series[0]\n","reviews_x = reviews[reviews[\"business_id\"] == business_x].reset_index(drop=True)\n","reviews_x"],"metadata":{"id":"HADK-kwc-52m","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1686186002087,"user_tz":420,"elapsed":214,"user":{"displayName":"Matteo Perona","userId":"07076841404597685331"}},"outputId":"ad230138-559c-4090-8eb8-4c5847efdab6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4bd48d08dcc0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbusiness_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbusiness_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbusiness_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreviews_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"business_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbusiness_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreviews_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","source":["stopwords = list(set(stopwords.words('english')))\n","print(stopwords)"],"metadata":{"id":"W7l6T4Kvqn7_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743911285,"user_tz":420,"elapsed":4,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"f39a64cc-9e50-4caa-8d02-0e1c278a1e34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['y', 'am', 'have', 'but', 'so', 'ours', \"hadn't\", \"weren't\", 'has', 'through', 'i', 'up', 'its', 'of', 'were', 'our', 'don', 'his', 'hers', 'at', 're', \"didn't\", 'off', 'are', 'my', \"you've\", 'than', 'is', 'me', 'did', 'why', 'all', 'as', \"wouldn't\", 'between', 'other', 's', 'very', 'mightn', 'where', 'about', 'having', 'yours', 'just', \"should've\", 'do', 'down', \"mightn't\", 'didn', 'because', 'their', \"isn't\", \"shan't\", 'again', 'here', \"mustn't\", 'does', \"don't\", 've', 'nor', 'not', 'in', 'what', \"needn't\", 'this', \"it's\", 'same', \"you'll\", 'an', 't', \"doesn't\", 'we', 'own', 'ma', 'if', 'or', \"shouldn't\", 'above', 'once', 'when', 'both', 'can', 'shan', 'mustn', \"couldn't\", 'by', 'theirs', 'after', \"hasn't\", 'to', 'hasn', 'being', 'yourselves', 'won', 'the', 'they', 'her', 'during', 'some', 'd', 'any', 'few', \"haven't\", 'more', 'until', \"she's\", 'm', 'these', 'for', 'under', 'which', 'on', 'himself', 'your', 'haven', 'should', 'them', 'too', 'itself', 'couldn', 'needn', 'o', \"that'll\", 'against', 'was', 'he', 'now', 'isn', 'herself', 'aren', 'myself', \"wasn't\", 'be', 'themselves', 'and', 'it', 'most', 'no', 'ourselves', \"you're\", 'a', \"you'd\", 'will', 'only', 'whom', 'out', 'before', 'had', 'there', 'each', 'who', 'such', 'wasn', 'below', 'weren', 'ain', 'wouldn', 'while', \"won't\", 'over', 'doing', 'that', 'you', 'yourself', 'shouldn', 'from', \"aren't\", 'll', 'those', 'hadn', 'further', 'with', 'doesn', 'been', 'how', 'him', 'she', 'into', 'then']\n"]}]},{"cell_type":"code","source":["#reviews_x.text.replace('|'.join(stopwords), '', regex=True)\n","reviews_x['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"],"metadata":{"id":"mIjeMFZ6sC8z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743911715,"user_tz":420,"elapsed":433,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"97c0e2c1-20f5-48b6-a4fd-b650a5f2a3b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       Locals recommended Milktooth, amazing jewel In...\n","1       Milktooth place go want good breakfast cocktai...\n","2       Busy place, offered extra- special coffee wait...\n","3       Creative food good. We get coffee tea wait sea...\n","4       Amazing comfortable atmosphere extremely uniqu...\n","                              ...                        \n","1416    Nice freely staff. Was bit disappointed learne...\n","1417    Arrived 1:30pm. Walked around looking find che...\n","1418    Verdict: A good brunch spot try new things Atm...\n","1419    For picky eater, place terrifying. While I'm g...\n","1420    So I've twice... This place gotten lot buzz la...\n","Name: text, Length: 1421, dtype: object"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["#### 2. Tokenize the reviews and find all unique tokens in the data.\n"],"metadata":{"id":"hZzX2I5rUtxq"}},{"cell_type":"code","source":["tokenized_reviews = reviews_x['text'].apply(\n","    lambda doc: pd.Series(nltk.word_tokenize(doc)).str.lower().to_numpy()\n","    )\n","\n","unique_tokens = np.unique(np.concatenate(tokenized_reviews))\n","\n","tokenized_reviews, unique_tokens"],"metadata":{"id":"C88eZJbIVM4l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743914330,"user_tz":420,"elapsed":2617,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"c41d0a78-e164-4e7b-fb74-7786cc5145e3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0       [locals, recommended, milktooth, ,, and, it, '...\n"," 1       [milktooth, is, the, place, to, go, if, you, w...\n"," 2       [busy, place, ,, but, we, were, offered, extra...\n"," 3       [creative, food, and, good, ., we, get, coffee...\n"," 4       [amazing, and, comfortable, atmosphere, with, ...\n","                               ...                        \n"," 1416    [nice, and, freely, staff, ., was, a, bit, dis...\n"," 1417    [arrived, at, 1:30pm, ., walked, around, looki...\n"," 1418    [verdict, :, a, good, brunch, spot, to, try, n...\n"," 1419    [for, a, picky, eater, ,, this, place, is, ter...\n"," 1420    [so, i, 've, been, here, twice, ..., this, pla...\n"," Name: text, Length: 1421, dtype: object,\n"," array(['!', '#', '$', ..., '~explosion', '\\u200b', '\\u200d'], dtype=object))"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"5lJqYaSJ--mA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. Create a matrix of tf-idf vectors for each review."],"metadata":{"id":"TJJ6VDULXie2"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer"],"metadata":{"id":"9FSGp_W3BBlG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#instantiate CountVectorizer()\n","cv=CountVectorizer()\n","\n","# this steps generates word counts for the words in your docs\n","word_count_vector=cv.fit_transform(reviews_x['text'])\n","word_count_vector.shape"],"metadata":{"id":"IUv4E4MCSang","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743914738,"user_tz":420,"elapsed":409,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"be4b9fbe-1289-4f70-fe2a-126f6081e275"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1421, 7849)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# count matrix\n","count_vector=cv.transform(reviews_x['text'])\n","\n","tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n","tfidf_transformer.fit(word_count_vector)\n","\n","\n","# tf-idf scores\n","tf_idf_vector=tfidf_transformer.transform(count_vector)\n","\n","feature_names = cv.get_feature_names_out()"],"metadata":{"id":"F42W0ZayO9kv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf_idf_vector.T.todense()"],"metadata":{"id":"uoEpEiYuTR7n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743914740,"user_tz":420,"elapsed":10,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"ff4bfcdc-e782-46b3-949a-68b9e6a75857"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["matrix([[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["#get tfidf vector for first document\n","first_document_vector=tf_idf_vector[0:10]\n","\n","#print the scores\n","df = pd.DataFrame(first_document_vector.T.todense(),\n","                  index=feature_names,\n","                  columns = [f'r{i}' for i in\n","                             range(first_document_vector.shape[0])])\n","\n","#df.sort_values(by=[\"r6\"],ascending=False)\n","#ser = df.iloc[:,0]\n","#ser\n","#ser.drop(labels = ['and'])"],"metadata":{"id":"YHGk0Ro0QkUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reviews_x['text']"],"metadata":{"id":"PNPY7ccRO2Ve","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743914740,"user_tz":420,"elapsed":7,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"237782e5-c940-4acb-a0e3-91eb8d64e087"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       Locals recommended Milktooth, and it's an amaz...\n","1       Milktooth is the place to go if you want a goo...\n","2       Busy place, but we were offered extra- special...\n","3       Creative food and good. We get coffee or tea w...\n","4       Amazing and comfortable atmosphere with extrem...\n","                              ...                        \n","1416    Nice and freely staff. Was a bit disappointed ...\n","1417    Arrived at 1:30pm.  Walked around looking to f...\n","1418    Verdict: A good brunch spot to try new things\\...\n","1419    For a picky eater, this place is terrifying. \\...\n","1420    So I've been here twice... This place has gott...\n","Name: text, Length: 1421, dtype: object"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":[],"metadata":{"id":"zOjvafpmvu_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from sklearn.cluster import KMeans\n","km = KMeans(n_clusters=8, init='random', max_iter=100, n_init=1, verbose=1)\n","km.fit(df)\n","labels = km.predict(df)\n","clusters = {}\n","n = 0\n","for item in labels:\n","  if n < len(df.columns):\n","    if item in clusters:\n","      clusters[item].append(df[\"r\" +str(n)])\n","    else:\n","      clusters[item] = [df[\"r\" +str(n)]]\n","    n +=1\n","  else:\n","    break\n","\n","for item in clusters:\n","  print(\"Cluster \", item)\n","  for i in clusters[item]:\n","    print( i)"],"metadata":{"id":"c_mRMc-ovvLM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685743915120,"user_tz":420,"elapsed":384,"user":{"displayName":"Niklas Chang","userId":"10876076688526287684"}},"outputId":"6022ecd8-f8dd-408f-fc2f-9861945a0f2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initialization complete\n","Iteration 0, inertia 10.0.\n","Iteration 1, inertia 8.13743692420152.\n","Iteration 2, inertia 7.496419253127968.\n","Iteration 3, inertia 7.0854092840625515.\n","Iteration 4, inertia 6.801376691838655.\n","Iteration 5, inertia 6.56818283167231.\n","Iteration 6, inertia 6.472166418498988.\n","Iteration 7, inertia 6.436518586454136.\n","Iteration 8, inertia 6.386055915031424.\n","Iteration 9, inertia 6.257312288886837.\n","Iteration 10, inertia 6.0680267795632865.\n","Iteration 11, inertia 6.015720401676517.\n","Iteration 12, inertia 5.994517875040576.\n","Iteration 13, inertia 5.9676790493030385.\n","Iteration 14, inertia 5.961516780360867.\n","Iteration 15, inertia 5.96012396174175.\n","Converged at iteration 15: strict convergence.\n","Cluster  0\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r0, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r1, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r2, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r3, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r4, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r5, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r6, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r7, Length: 7849, dtype: float64\n","00          0.0\n","000         0.0\n","00a         0.0\n","00am        0.0\n","00pm        0.0\n","           ... \n","zone        0.0\n","zoo         0.0\n","zooey       0.0\n","zoë         0.0\n","zucchini    0.0\n","Name: r8, Length: 7849, dtype: float64\n","00          0.000000\n","000         0.000000\n","00a         0.000000\n","00am        0.000000\n","00pm        0.000000\n","              ...   \n","zone        0.000000\n","zoo         0.000000\n","zooey       0.000000\n","zoë         0.000000\n","zucchini    0.122973\n","Name: r9, Length: 7849, dtype: float64\n"]}]},{"cell_type":"code","source":["labels"],"metadata":{"id":"9S6kSIwbv8Zk","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"error","timestamp":1686168737396,"user_tz":420,"elapsed":19,"user":{"displayName":"Matteo Perona","userId":"07076841404597685331"}},"outputId":"c889a166-b0db-4288-f4e7-a0c4c7af348a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0a1df294b701>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"]}]},{"cell_type":"markdown","source":["##DBSCAN"],"metadata":{"id":"gBOg1N4iXltD"}},{"cell_type":"code","source":["from sklearn.cluster import DBSCAN\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","df_normalized = scaler.fit_transform(df)\n","\n","dbscan = DBSCAN(eps=0.5, min_samples=5)\n","\n","dbscan.fit(df_normalized)\n","labels = dbscan.labels_\n","\n","clusters = {}\n","n = 0\n","for item in labels:\n","    if n < len(df.columns):\n","        if item != -1:\n","            if item in clusters:\n","                clusters[item].append(df[\"r\" + str(n)])\n","            else:\n","                clusters[item] = [df[\"r\" + str(n)]]\n","        n += 1\n","    else:\n","        break\n","\n","for item in clusters:\n","    print(\"Cluster\", item)\n","    for i in clusters[item]:\n","        print(i)"],"metadata":{"id":"QNBBcAzGXxV0"},"execution_count":null,"outputs":[]}]}